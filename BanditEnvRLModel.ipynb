{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7047fb2-7bcd-4466-a265-f7b7f8a798c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: pymysql in /opt/conda/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: sqlalchemy in /opt/conda/lib/python3.10/site-packages (2.0.30)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy) (3.0.3)\n",
      "Requirement already satisfied: mysql-connector-python in /opt/conda/lib/python3.10/site-packages (9.0.0)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "!pip install pymysql sqlalchemy\n",
    "!pip install mysql-connector-python python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c53c9d4-5f93-49fc-8dda-f7ae3147c483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        load_dotenv()\n",
    "        self.tidb_host = os.getenv(\"TIDB_HOST\", \"gateway01.us-east-1.prod.aws.tidbcloud.com\")\n",
    "        self.tidb_port = int(os.getenv(\"TIDB_PORT\", \"4000\"))\n",
    "        self.tidb_user = os.getenv(\"TIDB_USER\", \"EcFsmzHzn16sz32.root\")\n",
    "        self.tidb_password = os.getenv(\"TIDB_PASSWORD\", \"4UTXzVBKxU10w2Z1\")\n",
    "       # self.tidb_db_name = os.getenv(\"TIDB_DB_NAME\", \"embracepath\")\n",
    "        self.tidb_db_name = \"embracepath\"\n",
    "        self.ca_path = os.getenv(\"CA_PATH\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd935198-c68d-41ad-8a4e-57100907f4a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# db_service.py\n",
    "import mysql.connector\n",
    "from mysql.connector import MySQLConnection\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "class DatabaseService:\n",
    "    def __init__(self):\n",
    "        self.config = Config()\n",
    "        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    def get_connection(self, autocommit: bool = True) -> MySQLConnection:\n",
    "        db_conf = {\n",
    "            \"host\": self.config.tidb_host,\n",
    "            \"port\": self.config.tidb_port,\n",
    "            \"user\": self.config.tidb_user,\n",
    "            \"password\": self.config.tidb_password,\n",
    "            \"database\": self.config.tidb_db_name,\n",
    "            \"autocommit\": autocommit,\n",
    "            \"use_pure\": True,\n",
    "        }\n",
    "\n",
    "        if self.config.ca_path:\n",
    "            db_conf[\"ssl_verify_cert\"] = True\n",
    "            db_conf[\"ssl_verify_identity\"] = True\n",
    "            db_conf[\"ssl_ca\"] = self.config.ca_path\n",
    "\n",
    "        try:\n",
    "            connection = mysql.connector.connect(**db_conf)\n",
    "            return connection\n",
    "        except mysql.connector.Error as e:\n",
    "            logging.error(\"Error connecting to MySQL Platform: %s\", e)\n",
    "            return None\n",
    "    \n",
    "    def fetch_data(self, query: str, params: tuple = None) -> pd.DataFrame:\n",
    "        try:\n",
    "            with self.get_connection() as conn:\n",
    "                if params is not None:\n",
    "                    return pd.read_sql(query, conn, params=params)\n",
    "                else:\n",
    "                    return pd.read_sql(query, conn)\n",
    "        except Exception as e:\n",
    "            logging.error(\"Failed to fetch data: %s\", e)\n",
    "            return pd.DataFrame()  # Return an empty DataFrame on failure\n",
    "\n",
    "        \n",
    "        \n",
    "    def get_reward(self, state, exercise_id: int, emotion_id: int) -> float:\n",
    "        query = \"\"\"\n",
    "        SELECT feedback FROM user_exercise_feedback \n",
    "        WHERE user_id = %s AND exercise_id = %s AND emotion_id = %s\n",
    "        \"\"\"\n",
    "        feedback_df = self.fetch_data(query, (state.user_id, exercise_id, emotion_id))\n",
    "        if not feedback_df.empty:\n",
    "            return feedback_df['feedback'].values[0] / 5\n",
    "        else:\n",
    "            return 0.0  # or some default value\n",
    "\n",
    "        \n",
    "        \n",
    "            \n",
    "    def fetch_num_exercises(self):\n",
    "        query = \"SELECT COUNT(*) FROM recommended_exercise WHERE active_flg = TRUE\"\n",
    "        df = self.fetch_data(query)\n",
    "        if not df.empty:\n",
    "            return df.iloc[0, 0]\n",
    "        return 0\n",
    "            \n",
    "    def fetch_recommended_exercises(self):\n",
    "        query = \"\"\"\n",
    "        SELECT recommended_exercise_id, exercise_id, initial_q_value\n",
    "        FROM recommended_exercise\n",
    "        WHERE active_flg = TRUE\n",
    "        \"\"\"\n",
    "        return self.fetch_data(query)\n",
    "    \n",
    "    def get_emotion_vector_by_typename(self, typeName: str):\n",
    "        query = \"\"\"\n",
    "        USE embracepath;\n",
    "        SELECT \n",
    "        TypeID,\n",
    "        TypeName,\n",
    "        TypeNameVector,\n",
    "        Description,\n",
    "        DescriptionVector,\n",
    "        create_by,\n",
    "        create_dt,\n",
    "        modified_by,\n",
    "        modified_dt,\n",
    "        active_flg\n",
    "        FROM embracepath.lu_emotion_type WHERE TypeName = %s\n",
    "        \"\"\"\n",
    "        return self.fetch_data(query, params=(typeName,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcc9abeb-0dd2-43d3-9669-d0826e612a85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EpsilonGreedyAgent:\n",
    "    def __init__(self, epsilon, environment):\n",
    "        self.epsilon = epsilon\n",
    "        self.environment = environment\n",
    "        self.exercises_df = environment._fetch_recommended_exercises()\n",
    "        self.Q_values = np.zeros(len(self.exercises_df))  # Adjust size based on fetched data\n",
    "\n",
    "    def select_action(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            # Explore: choose a random action from the available exercises\n",
    "            action_idx = np.random.randint(len(self.exercises_df))\n",
    "        else:\n",
    "            # Exploit: choose the best known action\n",
    "            action_idx = np.argmax(self.Q_values)\n",
    "        action = self.exercises_df.iloc[action_idx]\n",
    "        return (action['recommended_exercise_id'], action['exercise_id'], action['initial_q_value'])\n",
    "\n",
    "    def update(self, action_idx, reward):\n",
    "        # Incremental update to the Q-value for the chosen action\n",
    "        self.Q_values[action_idx] += (reward - self.Q_values[action_idx]) / (self.environment.action_counts[action_idx] + 1)\n",
    "        self.environment.action_counts[action_idx] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f34affe-d99e-4fd2-9377-f042e2d7d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, core_emotion, user_id, emotion_vector):\n",
    "        self.core_emotion = core_emotion\n",
    "        self.user_id = user_id\n",
    "        self.emotion_vector = emotion_vector"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c163c0f2-9ad2-4265-8d6f-b2c3361488b5",
   "metadata": {},
   "source": [
    "class MindfulnessBanditEnv(gym.Env):\n",
    "    def __init__(self, num_features, db_service):\n",
    "        self.num_features = num_features\n",
    "        self.db_service = db_service\n",
    "        self.action_space = Discrete(10)  # 10 possible actions (mindfulness exercises)\n",
    "        self.state = None\n",
    "\n",
    "    def reset(self):\n",
    "        core_emotion = 0  # \"sadness\"\n",
    "        user_id = 123\n",
    "        emotion_vector = self.get_emotion_vector(\"sadness\")\n",
    "        self.state = State(core_emotion, user_id, emotion_vector)\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        # Simulate the delay between the selected mindfulness exercise and the user's rating\n",
    "        rating = self.get_user_rating(action)\n",
    "        reward = self.db_service.get_reward(self.state.user_id, action, rating)\n",
    "        return self.state, reward, True, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9aa09f3d-9f27-489e-9cb2-eaf8a19bebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "\n",
    "class MindfulnessBanditEnv(gym.Env):\n",
    "    def __init__(self, num_features:int, db_service:DatabaseService, num_actions:int):\n",
    "        self.num_features = num_features\n",
    "        self.db_service = db_service\n",
    "        self.action_space = Discrete(num_actions)  # 10 possible actions (mindfulness exercises)\n",
    "        self.observation_space = Box(low=0, high=1, shape=(num_features,), dtype=np.float32)\n",
    "        self.state = None\n",
    "        self.done = False\n",
    "\n",
    "    def reset(self):\n",
    "        core_emotion = 1 # Happiness\n",
    "        user_id = 1\n",
    "        emotion_vector = self.db_service.get_emotion_vector_by_typename(\"Happiness\")\n",
    "\n",
    "        emotion_vector = self.db_service.get_emotion_vector_by_typename(\"Happiness\")\n",
    "        self.state = State(core_emotion, user_id, emotion_vector)\n",
    "        observation = np.array([self.state.core_emotion, self.state.user_id, *self.state.emotion_vector]) # * is times the number of dimensions in the shape. in this it is 3\n",
    "        return observation\n",
    "\n",
    "    def step(self, action):\n",
    "        # Simulate the delay between the selected mindfulness exercise and the user's rating\n",
    "        rating = self.get_user_rating(action)\n",
    "        reward = self.db_service.get_reward(self.state, action, rating)\n",
    "        self.done = True\n",
    "        return self.state, reward, self.done, {}\n",
    "\n",
    "    def get_user_rating(self, action):\n",
    "        # Simulate the user's rating (1-5)\n",
    "        rating = np.random.randint(1, 6)\n",
    "        return rating\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b612a3b3-a7ac-4ea3-ac06-f18d3f6301a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class MindfulnessBanditEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Gymnasium environment for recommending mindfulness exercises using a contextual bandit approach.\n",
    "    Each state represents user features, and each action corresponds to recommending a specific exercise.\n",
    "    \"\"\"\n",
    "    metadata = {'render_modes': ['human', 'rgb_array'], 'render_fps': 30}\n",
    "\n",
    "    def __init__(self, num_features, num_actions):\n",
    "        super(MindfulnessBanditEnv, self).__init__()\n",
    "        self.num_features = num_features  # Number of features in each state vector\n",
    "       # self.engine = create_engine(self.db_url)\n",
    "        self.db_service = DatabaseService()  # Create an instance of DatabaseService\n",
    "\n",
    "        #self.action_space = spaces.Discrete(self._fetch_num_exercises())  # Set the number of actions based on DB\n",
    "        self.action_space = spaces.Discrete(num_actions)  # Set the number of actions based on DB\n",
    "        self.observation_space = spaces.Box(low=-1.0, high=1.0, shape=(num_features,), dtype=np.float32)\n",
    "\n",
    "\n",
    "    \n",
    "    def _fetch_feature_weights(self, action):\n",
    "        connection = self.db_service.get_connection()\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"SELECT feature_weights FROM recommended_exercises WHERE exercise_id = %s\", (action,))\n",
    "        weights = cursor.fetchone()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        return np.array(weights)\n",
    "\n",
    "    def step(self, action):\n",
    "        exercises = self.semantic_search()\n",
    "        chosen_exercise = exercises[action]\n",
    "        reward = 1.0 / (1.0 + chosen_exercise['DescriptionDistance'])  # Simulated reward based on similarity\n",
    "        done = True\n",
    "        return self.state, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        # Generate a new state vector for each episode\n",
    "        self.state = np.random.normal(0, 1, self.num_features)\n",
    "        return self.state\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        if mode == 'rgb_array':\n",
    "            return np.array([])  # Placeholder for actual rendering\n",
    "        elif mode == 'human':\n",
    "            print(f\"State: {self.state}\")\n",
    "            return None\n",
    "        def semantic_search(self):\n",
    "        query = \"\"\"\n",
    "        -- matches to exercise type lu_exercise_type\n",
    "        SELECT\n",
    "            e.exercise_id,\n",
    "            e.exercise_description,\n",
    "            l.TypeID,\n",
    "            l.TypeName,\n",
    "            l.Description,\n",
    "            VEC_COSINE_DISTANCE(e.description_vector, l.DescriptionVector) AS DescriptionDistance\n",
    "        FROM\n",
    "            exercise e\n",
    "        JOIN\n",
    "            lu_exercise_type l ON e.exercise_type = l.TypeID\n",
    "        ORDER BY\n",
    "            DescriptionDistance ASC\n",
    "        LIMIT 10;\n",
    "        \"\"\"\n",
    "        return self.db_service.fetch_data(query)\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57b87acd-cfde-49f1-af68-fbdf5f681667",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_2464/102851041.py:39: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql(query, conn, params=params)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m     env\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     42\u001b[0m     plot_learning_history(history)    \n\u001b[0;32m---> 44\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# def main(): \u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#     # Define the user's thought type - this will be user current state\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m \n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# main()    \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[36], line 36\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m history \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):  \u001b[38;5;66;03m# Simulate 5 episodes\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     state, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m     37\u001b[0m     action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m)  \u001b[38;5;66;03m# Randomly choose an action\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     next_state, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Create environment and agent\n",
    "# Function to plot the learning history\n",
    "def plot_learning_history(history):\n",
    "    fig = plt.figure(1, figsize=(14, 10))\n",
    "    ax = fig.add_subplot(2, 1, 1)\n",
    "    episodes = np.arange(len(history))\n",
    "    moves = np.array([h[0] for h in history])\n",
    "    plt.plot(episodes, moves, lw=4, marker='o', markersize=10)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    plt.xlabel('Episodes', size=20)\n",
    "    plt.ylabel('# moves', size=20)\n",
    "    ax = fig.add_subplot(2, 1, 2)\n",
    "    rewards = np.array([h[1] for h in history])\n",
    "    plt.step(episodes, rewards, lw=4)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    plt.xlabel('Episodes', size=20)\n",
    "    plt.ylabel('Final rewards', size=20)\n",
    "    plt.savefig('q-learning-history.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "def main():\n",
    "    # https://www.meta.ai/c/a04b014a-ece0-4c51-9aa0-c51efb911727\n",
    "    # for second set of eyes coding https://chatgpt.com/c/5264785b-a953-4241-b977-7a96b811d4bd\n",
    "    db_service = DatabaseService()\n",
    "    # The features are angry, sad, happy\n",
    "    env = MindfulnessBanditEnv(num_features=3, db_service=db_service, num_actions=10)\n",
    "    # so i need to create a custom state #     user_info = {\n",
    "#         'thought_pattern': 0,  # \"I'm not good enough\"\n",
    "#         'location': 0,  # \"at home\"\n",
    "#         'core_emotion': 0  # \"sadness\"\n",
    "#           'user_id': 123 $# user id\n",
    "#     } this is what i will be passing in. \n",
    "    \n",
    "    history = []\n",
    "    for episode in range(5):  # Simulate 5 episodes\n",
    "        state, _ = env.reset()\n",
    "        action = np.random.randint(0, 10)  # Randomly choose an action\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        history.append((episode, reward))\n",
    "        print(f\"Episode {episode}: Action {action}, Reward {reward}\")\n",
    "    env.close()\n",
    "    plot_learning_history(history)    \n",
    "    \n",
    "main()    \n",
    "\n",
    "\n",
    "\n",
    "# def main(): \n",
    "    \n",
    "#     # Define the user's thought type - this will be user current state\n",
    "#     user_info = {\n",
    "#         'thought_pattern': 0,  # \"I'm not good enough\"\n",
    "#         'location': 0,  # \"at home\"\n",
    "#         'core_emotion': 0  # \"sadness\"\n",
    "#           'user_id': 123 $# user id\n",
    "#     }\n",
    "#     num_features = 3 # number of input categories\n",
    "#     num_actions = 100\n",
    "#     env = MindfulnessBanditEnv(num_features, num_actions)\n",
    "#     q_values = np.zeros(num_actions)\n",
    "#     agent = EpsilonGreedyAgent(epsilon=0.1, environment=env)\n",
    "\n",
    "#     history = []\n",
    "#     alpha = 0.1\n",
    "#     gamma = 0.9\n",
    "\n",
    "#     for episode in range(1000):\n",
    "#         state = env.reset()\n",
    "#         action = agent.select_action(state)\n",
    "#         print(\"action is\", action)\n",
    "#         next_state, reward, done, _ = env.step(action)\n",
    "#         agent.update(action, reward, alpha, gamma)\n",
    "#         history.append((action, reward))\n",
    "#         if episode % 100 == 0:\n",
    "#             print(f\"Episode {episode}: Action {action}, Reward {reward}\")\n",
    "\n",
    "#     env.close()\n",
    "#     plot_learning_history(history)\n",
    "\n",
    "# main()    \n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m122"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
