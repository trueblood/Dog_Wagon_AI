{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9533cbf-9791-48e3-8c42-24fa1be8688c",
   "metadata": {},
   "source": [
    "Tabular Q-learning uses a table to store the Q-values for each state-action pair. This approach works well for small to medium-sized problems, where the number of states and actions is relatively small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7047fb2-7bcd-4466-a265-f7b7f8a798c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: pymysql in /opt/conda/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: sqlalchemy in /opt/conda/lib/python3.10/site-packages (2.0.30)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy) (3.0.3)\n",
      "Requirement already satisfied: mysql-connector-python in /opt/conda/lib/python3.10/site-packages (9.0.0)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: sqlalchemy in /opt/conda/lib/python3.10/site-packages (2.0.30)\n",
      "Requirement already satisfied: mysql-connector-python in /opt/conda/lib/python3.10/site-packages (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "!pip install pymysql sqlalchemy\n",
    "!pip install mysql-connector-python python-dotenv\n",
    "!pip install sqlalchemy mysql-connector-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4c53c9d4-5f93-49fc-8dda-f7ae3147c483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "from sqlalchemy import text\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        load_dotenv()\n",
    "        self.tidb_host = os.getenv(\"TIDB_HOST\", \"gateway01.us-east-1.prod.aws.tidbcloud.com\")\n",
    "        self.tidb_port = int(os.getenv(\"TIDB_PORT\", \"4000\"))\n",
    "        self.tidb_user = os.getenv(\"TIDB_USER\", \"EcFsmzHzn16sz32.root\")\n",
    "        self.tidb_password = os.getenv(\"TIDB_PASSWORD\", \"4UTXzVBKxU10w2Z1\")\n",
    "       # self.tidb_db_name = os.getenv(\"TIDB_DB_NAME\", \"embracepath\")\n",
    "        self.tidb_db_name = \"embracepath\"\n",
    "        self.ca_path = os.getenv(\"CA_PATH\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "35d9ddaf-3bd3-4cc3-a475-9a5514828a87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LuTypeTable:\n",
    "    def __init__(self, TypeID, TypeName, TypeNameVector, Description, DescriptionVector, create_by, create_dt, modified_by, modified_dt, active_flg):\n",
    "        self.TypeID = TypeID\n",
    "        self.TypeName = TypeName\n",
    "        self.TypeNameVector = TypeNameVector\n",
    "        self.Description = Description\n",
    "        self.DescriptionVector = DescriptionVector\n",
    "        self.create_by = create_by\n",
    "        self.create_dt = create_dt\n",
    "        self.modified_by = modified_by\n",
    "        self.modified_dt = modified_dt\n",
    "        self.active_flg = active_flg\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'TypeID': self.TypeID,\n",
    "            'TypeName': self.TypeName,\n",
    "            'TypeNameVector': self.TypeNameVector,\n",
    "            'Description': self.Description,\n",
    "            'DescriptionVector': self.DescriptionVector,\n",
    "            'create_by': self.create_by,\n",
    "            'create_dt': self.create_dt,\n",
    "            'modified_by': self.modified_by,\n",
    "            'modified_dt': self.modified_dt,\n",
    "            'active_flg': self.active_flg\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a01b2aff-0c02-487c-bcbf-a16ffc17d119",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "class DatabaseService:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "        self.engine = self.create_engine()\n",
    "\n",
    "    def create_engine(self):\n",
    "        # Construct the database URL\n",
    "        database_url = f\"mysql+mysqlconnector://{self.config.tidb_user}:{self.config.tidb_password}@{self.config.tidb_host}:{self.config.tidb_port}/{self.config.tidb_db_name}\"\n",
    "        if self.config.ca_path:\n",
    "            connect_args = {\n",
    "                'ssl_ca': self.config.ca_path,\n",
    "                'ssl_verify_cert': True,\n",
    "                'ssl_verify_identity': True\n",
    "            }\n",
    "            return create_engine(database_url, connect_args=connect_args)\n",
    "        return create_engine(database_url)\n",
    "    \n",
    "    # def fetch_data_with_cursor(self, query: str) -> Dict:\n",
    "    #     self.connect()\n",
    "    #     try:\n",
    "    #         cursor = self.connection.cursor()\n",
    "    #         cursor.execute(query)\n",
    "    #         result = cursor.fetchall()\n",
    "    #         cursor.close()\n",
    "    #         return {row[0]: dict(zip([col[0] for col in cursor.description[1:]], row[1:])) for row in result}\n",
    "    #     except Error as e:\n",
    "    #         print(f\"Error: {e}\")\n",
    "    #         return {}\n",
    "    #     finally:\n",
    "    #         self.disconnect()\n",
    "\n",
    "    def fetch_data(self, query: str, params=None):\n",
    "        try:\n",
    "            if params:\n",
    "                print(\"Params Type:\", {type(p) for p in params})\n",
    "                print(\"Params Value:\", params)\n",
    "                print(\"with params\")\n",
    "                print(\"query is :\", query)\n",
    "                df = pd.read_sql(query, self.engine, params=params)\n",
    "                return df\n",
    "            else:\n",
    "                print(\"without params\")\n",
    "                return pd.read_sql(query, self.engine)\n",
    "        except Exception as e:\n",
    "            logging.error(\"Failed to fetch data: %s\", e)\n",
    "            return pd.DataFrame()  # Return an empty DataFrame on failure\n",
    "    \n",
    "    def execute(self, query: str, params=None):\n",
    "        try:\n",
    "            print(\"Executing SQL Query:\")\n",
    "            print(\"Query:\", query)\n",
    "            print(\"Parameters:\", params)\n",
    "\n",
    "            with self.engine.begin() as connection:  # Transaction management\n",
    "                result = connection.execute(query, params)\n",
    "                affected_rows = result.rowcount\n",
    "                print(f\"Rows affected: {affected_rows}\")\n",
    "                return affected_rows\n",
    "        except Exception as e:\n",
    "            logging.error(\"Failed to execute query: %s\", str(e))\n",
    "            print(\"Error during SQL execution:\", str(e))\n",
    "            return None\n",
    "\n",
    "\n",
    "    def get_reward(self, user_id: int, exercise_id: int, emotion_id: int) -> float:\n",
    "        user_id=1 # will need to remove once data is in user_exercise_feedback\n",
    "        exercise_id=2956 # willl need to remove once data is in user_exercise_feedback\n",
    "        emotion_id = 3 # willl need to remove once data is in user_exercise_feedback\n",
    "        print(\"in get_reward\")\n",
    "        query = \"\"\"\n",
    "        SELECT * FROM user_exercise_feedback\n",
    "        WHERE user_id = %s AND exercise_id = %s AND emotion_id = %s\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"user_id is \", user_id)\n",
    "        print(\"exercise_id is \", exercise_id)\n",
    "        print(\"emotion_id is \", emotion_id)\n",
    "        \n",
    "       # feedback_df = self.fetch_data(query, params=(user_id, exercise_id, emotion_id))\n",
    "        feedback_df = self.fetch_data(query, params=[(user_id, exercise_id, emotion_id)])\n",
    "\n",
    "        print(\"feedback_df is \", feedback_df.head)\n",
    "        if not feedback_df.empty:\n",
    "            return feedback_df['feedback'].iloc[0] / 5.0\n",
    "        else:\n",
    "            return 0.0  # Return a default value when no feedback is available\n",
    "\n",
    "    def fetch_num_exercises(self):\n",
    "        query = \"SELECT COUNT(*) FROM recommended_exercise WHERE active_flg = TRUE\"\n",
    "        df = self.fetch_data(query)\n",
    "        if not df.empty:\n",
    "            return df.iloc[0, 0]\n",
    "        return 0\n",
    "\n",
    "    def fetch_recommended_exercises(self):\n",
    "        query = \"\"\"\n",
    "        SELECT recommended_exercise_id, exercise_id, initial_q_value\n",
    "        FROM recommended_exercise\n",
    "        WHERE active_flg = TRUE\n",
    "        \"\"\"\n",
    "        return self.fetch_data(query)\n",
    "\n",
    "    def get_emotion_vector_by_typename(self, typeName: str):\n",
    "        query = \"\"\"\n",
    "        SELECT TypeID, TypeName, TypeNameVector, Description, DescriptionVector,\n",
    "        create_by, create_dt, modified_by, modified_dt, active_flg\n",
    "        FROM lu_emotion_type WHERE TypeName = %s\n",
    "        \"\"\"\n",
    "        return self.fetch_data(query, params=(typeName,))\n",
    "    \n",
    "    def update_q_value(self, user_id, core_emotion_id, core_emotion, emotion_vector, action, q_value, modified_by):\n",
    "        query = \"\"\"\n",
    "        UPDATE q_table\n",
    "        SET q_value = %s, modified_by = %s, modified_dt = CURRENT_TIMESTAMP\n",
    "        WHERE user_id = %s AND core_emotion_id = %s AND core_emotion = %s AND emotion_vector = %s AND action = %s\n",
    "        \"\"\"\n",
    "        self.execute(query, (q_value, modified_by, user_id, core_emotion_id, core_emotion, emotion_vector, action))\n",
    "        result = connection.execute(query)\n",
    "        return self.execute(query, (q_table_id, user_id, core_emotion_id, core_emotion, emotion_vector, action, q_value, create_by))\n",
    "\n",
    "    def insert_q_value(self, q_table_id, user_id, core_emotion_id, core_emotion, emotion_vector, action, q_value, create_by):\n",
    "        query = \"\"\"\n",
    "        INSERT INTO q_table (\n",
    "            q_table_id, user_id, core_emotion_id, core_emotion, emotion_vector, action, q_value, create_by, create_dt\n",
    "        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, CURRENT_TIMESTAMP)\n",
    "        \"\"\"\n",
    "        params = (q_table_id, user_id, core_emotion_id, core_emotion, emotion_vector, action, q_value, create_by)\n",
    "\n",
    "        try:\n",
    "            # Use raw DB-API connection accessible via `connection.connection`\n",
    "            with self.engine.raw_connection() as raw_conn:\n",
    "                cursor = raw_conn.cursor()\n",
    "                cursor.execute(query, params)\n",
    "                raw_conn.commit()  # Commit the transaction manually\n",
    "                affected_rows = cursor.rowcount\n",
    "                cursor.close()\n",
    "                return affected_rows\n",
    "        except SQLAlchemyError as e:\n",
    "            logging.error(f\"Failed to execute query: {e}\")\n",
    "            return None\n",
    "\n",
    "    def get_q_values(self):\n",
    "        query = \"\"\"\n",
    "        SELECT user_id, core_emotion_id, core_emotion, emotion_vector, action, q_value\n",
    "        FROM q_table\n",
    "        WHERE active_flg = TRUE\n",
    "        \"\"\"\n",
    "        return self.fetch_data(query)\n",
    "    \n",
    "    def fetch_exercise_data(self):\n",
    "        query = \"SELECT * FROM exercise\"\n",
    "        return self.fetch_data(query)\n",
    "    \n",
    "    def fetch_latest_emotional_state(self):\n",
    "        query = \"SELECT * FROM embracepath.user_emotional_state ORDER BY create_dt LIMIT 1\"\n",
    "        return self.fetch_data(query)\n",
    "    \n",
    "\n",
    "    # def fetch_exercises(self):\n",
    "    #     query = \"\"\"\n",
    "    #     SELECT * FROM exercise\n",
    "    #     \"\"\"\n",
    "    #     exercise_records = self.fetch_data(query)\n",
    "    #     exercises = [\n",
    "    #         Exercise(\n",
    "    #             exercise_id=rec[0], exercise_name=rec[1], exercise_vector=rec[2], \n",
    "    #             exercise_location=rec[3], exercise_type=rec[4], exercise_description=rec[5], \n",
    "    #             description_vector=rec[6], exercise_parent_child_type_id=rec[7], \n",
    "    #             create_by=rec[8], create_dt=rec[9], modified_by=rec[10], \n",
    "    #             modified_dt=rec[11], active_flg=rec[12]\n",
    "    #         )\n",
    "    #         for rec in exercise_records\n",
    "    #     ]\n",
    "    #     return exercises\n",
    "    \n",
    "        \n",
    "        \n",
    "#     def get_exercises(cursor: MySQLCursor) -> List[Exercise]:\n",
    "#         try:\n",
    "#             tableName = 'exercise'\n",
    "#             cursor.execute(f\"SELECT * FROM {tableName}\")\n",
    "#             rows = cursor.fetchall()  # Retrieve all rows at once\n",
    "#             exercises = []  # List to store Exercise objects\n",
    "\n",
    "#             for row in rows:\n",
    "#                 exercise = Exercise(\n",
    "#                     exercise_id=row[0],\n",
    "#                     exercise_name=row[1],\n",
    "#                     exercise_vector=json.loads(row[2]),  # Converting JSON string back to list\n",
    "#                     exercise_location=row[3],\n",
    "#                     exercise_type=row[4],\n",
    "#                     exercise_description=row[5],\n",
    "#                     description_vector=json.loads(row[6]),  # Converting JSON string back to list\n",
    "#                     exercise_parent_child_type_id=row[7],\n",
    "#                     create_by=row[8],\n",
    "#                     create_dt=row[9],\n",
    "#                     modified_by=row[10],\n",
    "#                     modified_dt=row[11],\n",
    "#                     active_flg=row[12]\n",
    "#                 )\n",
    "#                 exercises.append(exercise)  # Add the Exercise object to the list\n",
    "\n",
    "#             return exercises  # Return the list of Exercise objects\n",
    "#         except mysql.connector.Error as e:\n",
    "#             logging.error(\"Error fetching records: %s\", e)\n",
    "#             return []  # Return an empty list in case of an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fcc9abeb-0dd2-43d3-9669-d0826e612a85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EpsilonGreedyAgent:\n",
    "    def __init__(self, epsilon, environment):\n",
    "        self.epsilon = epsilon\n",
    "        self.environment = environment\n",
    "        self.exercises_df = environment._fetch_recommended_exercises()\n",
    "        self.Q_values = np.zeros(len(self.exercises_df))  # Adjust size based on fetched data\n",
    "\n",
    "    def select_action(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            # Explore: choose a random action from the available exercises\n",
    "            action_idx = np.random.randint(len(self.exercises_df))\n",
    "        else:\n",
    "            # Exploit: choose the best known action\n",
    "            action_idx = np.argmax(self.Q_values)\n",
    "        action = self.exercises_df.iloc[action_idx]\n",
    "        return (action['recommended_exercise_id'], action['exercise_id'], action['initial_q_value'])\n",
    "\n",
    "    def update(self, action_idx, reward):\n",
    "        # Incremental update to the Q-value for the chosen action\n",
    "        self.Q_values[action_idx] += (reward - self.Q_values[action_idx]) / (self.environment.action_counts[action_idx] + 1)\n",
    "        self.environment.action_counts[action_idx] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8f34affe-d99e-4fd2-9377-f042e2d7d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, core_emotion=None, user_id=None, emotion_vector=None, core_emotion_id=None, location_vector=None):\n",
    "        self.core_emotion = core_emotion\n",
    "        self.core_emotion_id = core_emotion_id\n",
    "        self.user_id = user_id\n",
    "        self.emotion_vector = emotion_vector\n",
    "        self.location_vector = location_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9aa09f3d-9f27-489e-9cb2-eaf8a19bebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "\n",
    "class MindfulnessBanditEnv(gym.Env):\n",
    "    def __init__(self, num_features:int, db_service:DatabaseService, num_actions:int):\n",
    "        self.num_features = num_features\n",
    "        self.db_service = db_service\n",
    "        self.action_space = Discrete(num_actions)  # 10 possible actions (mindfulness exercises)\n",
    "        self.observation_space = Box(low=0, high=1, shape=(num_features,), dtype=np.float32)\n",
    "        self.state = None\n",
    "        self.done = False\n",
    "        self.Q_A = {}  # Q-value estimate for action selection\n",
    "        self.Q_B = {}  # Q-value estimate for updating\n",
    "        self.alpha = 0.1  # Learning rate\n",
    "        self.gamma = 0.9  # Discount factor\n",
    "        self.q_values_history = []  # To store Q-values for plotting\n",
    "        self.actions = self.get_exercises()\n",
    "        self.update_action_space()  # Update action space based on retrieved exercises\n",
    "    \n",
    "    def reset(self):\n",
    "        core_emotion = 1 # Happiness\n",
    "        user_id = 1\n",
    "        emotion_vector_df = self.db_service.get_emotion_vector_by_typename(\"Happy\")\n",
    "\n",
    "        # Create an instance of LuTypeTable from the first row of the DataFrame\n",
    "        emotion_vector = LuTypeTable(\n",
    "            TypeID=emotion_vector_df.iloc[0]['TypeID'],\n",
    "            TypeName=emotion_vector_df.iloc[0]['TypeName'],\n",
    "            TypeNameVector=emotion_vector_df.iloc[0]['TypeNameVector'],\n",
    "            Description=emotion_vector_df.iloc[0]['Description'],\n",
    "            DescriptionVector=emotion_vector_df.iloc[0]['DescriptionVector'],\n",
    "            create_by=emotion_vector_df.iloc[0]['create_by'],\n",
    "            create_dt=emotion_vector_df.iloc[0]['create_dt'],\n",
    "            modified_by=emotion_vector_df.iloc[0]['modified_by'],\n",
    "            modified_dt=emotion_vector_df.iloc[0]['modified_dt'],\n",
    "            active_flg=emotion_vector_df.iloc[0]['active_flg']\n",
    "        )\n",
    "        #print(\"emotion_vector is\", emotion_vector.DescriptionVector)\n",
    "      #  print(\"before self.state\")\n",
    "        \n",
    "#         emotion_vector_list = [float(x) for x in emotion_vector.TypeNameVector.strip('[]').split(',')]\n",
    "\n",
    "#         # Print each element of the list\n",
    "#         for element in emotion_vector_list:\n",
    "#             print(element)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        st = State()\n",
    "        st.core_emotion = emotion_vector.TypeName\n",
    "        st.user_id = user_id\n",
    "        st.emotion_vector = emotion_vector.TypeNameVector\n",
    "        st.core_emotion_id = emotion_vector.TypeID\n",
    "        st.location_vector = [0] * 384\n",
    "        self.state = st\n",
    "        \n",
    "        print(\"state variables\\n\")\n",
    "        print(\"core_emotion is\", user_id)\n",
    "       # print(\"TypeNameVector is\", emotion_vector.TypeNameVector)\n",
    "        print(\"TypeID is\", emotion_vector.TypeID)\n",
    "\n",
    "        \n",
    "        #self.state = State(core_emotion=emotion_vector.TypeName, user_id=user_id, emotion_vector=[float(x) for x in emotion_vector.TypeNameVector.split(',')], core_emotion_id=emotion_vector.TypeID)\n",
    "\n",
    "        #self.state = State(core_emotion=emotion_vector.TypeName, user_id=user_id, emotion_vector=emotion_vector.TypeNameVector, core_emotion_id=emotion_vector.TypeID)\n",
    "        observation = np.array([self.state.core_emotion, self.state.user_id, *self.state.emotion_vector, self.state.core_emotion_id])\n",
    "       # print(\"after self.state\")\n",
    "        return observation\n",
    "    \n",
    "    \n",
    "    def save_q_value(self, state, action, reward):\n",
    "        state_tuple = (state.core_emotion, state.user_id, tuple(state.emotion_vector), state.core_emotion_id)\n",
    "        q_dict = self.Q_B if action % 2 == 0 else self.Q_A\n",
    "        q_value = q_dict.get((state_tuple, action), 0)\n",
    "        q_dict[(state_tuple, action)] = q_value + reward\n",
    "        # Record the maximum Q-value for this state for plotting purposes\n",
    "        self.q_values_history.append(max(q_dict.values()))\n",
    "    # def save_q_value(self, state, action, reward):\n",
    "    #     state_tuple = (state.core_emotion, state.user_id, tuple(state.emotion_vector), state.core_emotion_id)\n",
    "    #     q_dict = self.Q_B if action % 2 == 0 else self.Q_A\n",
    "    #     q_value = q_dict.get((state_tuple, action), 0)\n",
    "    #     q_dict[(state_tuple, action)] = q_value + reward  # Example update, adjust your learning rule\n",
    "\n",
    "        # Save the Q-value to the database\n",
    "       # self.db_service.insert_q_value(1, state.user_id, state.core_emotion_id, state.core_emotion, state.emotion_vector, action, q_value, \"RL_Model\")\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Simulate the delay between the selected mindfulness exercise and the user's rating\n",
    "        rating = self.get_user_rating(action) # this will be switched out by the feedback table. TODO!!!!!\n",
    "        reward = self.db_service.get_reward(self.state, action, rating)\n",
    "        print(\"reward is \", reward)\n",
    "        # Update Q-values using Double Q-learning\n",
    "        self.update_Q_values(self.state, action, reward)\n",
    "        self.done = True\n",
    "        print(\"Q Values are updated\")\n",
    "        self.save_q_value(self.state, action, reward) # this throws the bugs\n",
    "        return self.state, reward, self.done, {}    \n",
    "\n",
    "    def get_user_rating(self, action):\n",
    "        # Simulate the user's rating (1-5)\n",
    "        rating = np.random.randint(1, 6)\n",
    "        return rating\n",
    "    \n",
    "    def update_Q_values(self, state, action, reward):\n",
    "        print(\"in update_Q_values\")\n",
    "        # Get Q-values for state-action pair\n",
    "        q_value_A = self.Q_A.get((state, action), 0)\n",
    "       # q_value_B = self.get_second_q_value(state, action) # i will need to add this back, TODO!!!!\n",
    "        q_value_B = 0.1\n",
    "\n",
    "        # Update Q-value estimate for action selection (Q_A)\n",
    "        self.Q_A[(state, action)] = reward\n",
    "\n",
    "        # Update Q-value estimate for updating (Q_B)\n",
    "        self.Q_B[(state, action)] = reward\n",
    "\n",
    "    def get_second_q_value(self, state, action):\n",
    "        # Get second Q-value using vector search query\n",
    "        query = \"\"\"\n",
    "        SELECT q_value\n",
    "        FROM q_table\n",
    "        WHERE state = %s AND action = %s\n",
    "        \"\"\"\n",
    "        result = self.db_service.fetch_data(query, (state, action))\n",
    "        if result.empty:\n",
    "            return 0  # Return a default Q-value if none is found\n",
    "        return result.iloc[0, 0]\n",
    "    \n",
    "    # def load_exercises(self):\n",
    "    #     # Get a cursor from the database service\n",
    "    #     cursor = self.db_service.get_cursor()\n",
    "    #     # Retrieve exercises from the database\n",
    "    #     exercises = fetch_exercises\n",
    "    #     return exercises\n",
    "    \n",
    "    def update_action_space(self):\n",
    "        # Update the number of actions based on the number of exercises retrieved\n",
    "        self.num_actions = len(self.actions)\n",
    "        self.action_space = Discrete(self.num_actions)  # Reset action space with the actual number of exercises\n",
    "        \n",
    "    def get_exercises(self):\n",
    "        exercise_df =  self.db_service.fetch_exercise_data()\n",
    "        exercises = [\n",
    "            Exercise(\n",
    "                exercise_id=row['exercise_id'], exercise_name=row['exercise_name'], exercise_vector=row['exercise_vector'],\n",
    "                exercise_location=row['exercise_location'], exercise_type=row['exercise_type'], exercise_description=row['exercise_description'],\n",
    "                description_vector=row['description_vector'], exercise_parent_child_type_id=row['exercise_parent_child_type_id'],\n",
    "                create_by=row['create_by'], create_dt=row['create_dt'], modified_by=row['modified_by'],\n",
    "                modified_dt=row['modified_dt'], active_flg=row['active_flg']\n",
    "            )\n",
    "            for index, row in exercise_df.iterrows()\n",
    "        ]\n",
    "        return exercises\n",
    "  \n",
    "    def get_most_recent_state(self):\n",
    "        df_user_state = self.db_service.fetch_latest_emotional_state()\n",
    "        state = State(\n",
    "            emotion_vector=df_user_state.iloc[0]['emotion_vector'],\n",
    "            location_vector=df_user_state.iloc[0]['location_vector']\n",
    "        )\n",
    "        return state\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    # def get_exercise_count(self):\n",
    "    #     result = self.db_service.fetch_data(query, (state, action))\n",
    "    #     if result.empty:\n",
    "    #         return 0  # Return a default Q-value if none is found\n",
    "    #     return result\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7529ea44-c639-42e1-ac54-ff90b9eeac35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Exercise:\n",
    "    def __init__(self, exercise_id, exercise_name, exercise_vector, exercise_location, exercise_type, \n",
    "                 exercise_description, description_vector, exercise_parent_child_type_id, \n",
    "                 create_by, create_dt, modified_by=None, modified_dt=None, active_flg=True):\n",
    "        self.exercise_id = exercise_id\n",
    "        self.exercise_name = exercise_name\n",
    "        self.exercise_vector = exercise_vector\n",
    "        self.exercise_location = exercise_location\n",
    "        self.exercise_type = exercise_type\n",
    "        self.exercise_description = exercise_description\n",
    "        self.description_vector = description_vector\n",
    "        self.exercise_parent_child_type_id = exercise_parent_child_type_id\n",
    "        self.create_by = create_by\n",
    "        self.create_dt = create_dt  # Will be set to current datetime in the database\n",
    "        self.modified_by = modified_by\n",
    "        self.modified_dt = modified_dt\n",
    "        self.active_flg = active_flg\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"exercise_id\": self.exercise_id,\n",
    "            \"exercise_name\": self.exercise_name,\n",
    "            \"exercise_vector\": self.exercise_vector,\n",
    "            \"exercise_location\": self.exercise_location,\n",
    "            \"exercise_type\": self.exercise_type,\n",
    "            \"exercise_description\": self.exercise_description,\n",
    "            \"description_vector\": self.description_vector,\n",
    "            \"exercise_parent_child_type_id\": self.exercise_parent_child_type_id,\n",
    "            \"create_by\": self.create_by,\n",
    "            \"create_dt\": self.create_dt,  # Although it's set in the DB, it can be included if set in Python\n",
    "            \"modified_by\": self.modified_by,\n",
    "            \"modified_dt\": self.modified_dt,\n",
    "            \"active_flg\": self.active_flg\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "57b87acd-cfde-49f1-af68-fbdf5f681667",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without params\n",
      "without params\n",
      "most_recent_state is <__main__.State object at 0x7f320d377a60>\n",
      "Params Type: {<class 'str'>}\n",
      "Params Value: ('Happy',)\n",
      "with params\n",
      "query is : \n",
      "        SELECT TypeID, TypeName, TypeNameVector, Description, DescriptionVector,\n",
      "        create_by, create_dt, modified_by, modified_dt, active_flg\n",
      "        FROM lu_emotion_type WHERE TypeName = %s\n",
      "        \n",
      "state variables\n",
      "\n",
      "core_emotion is 1\n",
      "TypeID is 1\n",
      "current number of actions in the env  9647\n",
      "in get_reward\n",
      "user_id is  1\n",
      "exercise_id is  2956\n",
      "emotion_id is  3\n",
      "Params Type: {<class 'tuple'>}\n",
      "Params Value: [(1, 2956, 3)]\n",
      "with params\n",
      "query is : \n",
      "        SELECT * FROM user_exercise_feedback\n",
      "        WHERE user_id = %s AND exercise_id = %s AND emotion_id = %s\n",
      "        \n",
      "feedback_df is  <bound method NDFrame.head of    user_exercise_feedback_id  user_id  exercise_id  emotion_id  feedback  \\\n",
      "0                          1        1         2956           3         4   \n",
      "\n",
      "  create_by           create_dt modified_by modified_dt  active_flg  \n",
      "0     admin 2024-08-15 11:03:29        None        None           1  >\n",
      "reward is  0.8\n",
      "in update_Q_values\n",
      "Q Values are updated\n",
      "Params Type: {<class 'str'>}\n",
      "Params Value: ('Happy',)\n",
      "with params\n",
      "query is : \n",
      "        SELECT TypeID, TypeName, TypeNameVector, Description, DescriptionVector,\n",
      "        create_by, create_dt, modified_by, modified_dt, active_flg\n",
      "        FROM lu_emotion_type WHERE TypeName = %s\n",
      "        \n",
      "state variables\n",
      "\n",
      "core_emotion is 1\n",
      "TypeID is 1\n",
      "current number of actions in the env  9647\n",
      "in get_reward\n",
      "user_id is  1\n",
      "exercise_id is  2956\n",
      "emotion_id is  3\n",
      "Params Type: {<class 'tuple'>}\n",
      "Params Value: [(1, 2956, 3)]\n",
      "with params\n",
      "query is : \n",
      "        SELECT * FROM user_exercise_feedback\n",
      "        WHERE user_id = %s AND exercise_id = %s AND emotion_id = %s\n",
      "        \n",
      "feedback_df is  <bound method NDFrame.head of    user_exercise_feedback_id  user_id  exercise_id  emotion_id  feedback  \\\n",
      "0                          1        1         2956           3         4   \n",
      "\n",
      "  create_by           create_dt modified_by modified_dt  active_flg  \n",
      "0     admin 2024-08-15 11:03:29        None        None           1  >\n",
      "reward is  0.8\n",
      "in update_Q_values\n",
      "Q Values are updated\n",
      "Params Type: {<class 'str'>}\n",
      "Params Value: ('Happy',)\n",
      "with params\n",
      "query is : \n",
      "        SELECT TypeID, TypeName, TypeNameVector, Description, DescriptionVector,\n",
      "        create_by, create_dt, modified_by, modified_dt, active_flg\n",
      "        FROM lu_emotion_type WHERE TypeName = %s\n",
      "        \n",
      "state variables\n",
      "\n",
      "core_emotion is 1\n",
      "TypeID is 1\n",
      "current number of actions in the env  9647\n",
      "in get_reward\n",
      "user_id is  1\n",
      "exercise_id is  2956\n",
      "emotion_id is  3\n",
      "Params Type: {<class 'tuple'>}\n",
      "Params Value: [(1, 2956, 3)]\n",
      "with params\n",
      "query is : \n",
      "        SELECT * FROM user_exercise_feedback\n",
      "        WHERE user_id = %s AND exercise_id = %s AND emotion_id = %s\n",
      "        \n",
      "feedback_df is  <bound method NDFrame.head of    user_exercise_feedback_id  user_id  exercise_id  emotion_id  feedback  \\\n",
      "0                          1        1         2956           3         4   \n",
      "\n",
      "  create_by           create_dt modified_by modified_dt  active_flg  \n",
      "0     admin 2024-08-15 11:03:29        None        None           1  >\n",
      "reward is  0.8\n",
      "in update_Q_values\n",
      "Q Values are updated\n",
      "Params Type: {<class 'str'>}\n",
      "Params Value: ('Happy',)\n",
      "with params\n",
      "query is : \n",
      "        SELECT TypeID, TypeName, TypeNameVector, Description, DescriptionVector,\n",
      "        create_by, create_dt, modified_by, modified_dt, active_flg\n",
      "        FROM lu_emotion_type WHERE TypeName = %s\n",
      "        \n",
      "state variables\n",
      "\n",
      "core_emotion is 1\n",
      "TypeID is 1\n",
      "current number of actions in the env  9647\n",
      "in get_reward\n",
      "user_id is  1\n",
      "exercise_id is  2956\n",
      "emotion_id is  3\n",
      "Params Type: {<class 'tuple'>}\n",
      "Params Value: [(1, 2956, 3)]\n",
      "with params\n",
      "query is : \n",
      "        SELECT * FROM user_exercise_feedback\n",
      "        WHERE user_id = %s AND exercise_id = %s AND emotion_id = %s\n",
      "        \n",
      "feedback_df is  <bound method NDFrame.head of    user_exercise_feedback_id  user_id  exercise_id  emotion_id  feedback  \\\n",
      "0                          1        1         2956           3         4   \n",
      "\n",
      "  create_by           create_dt modified_by modified_dt  active_flg  \n",
      "0     admin 2024-08-15 11:03:29        None        None           1  >\n",
      "reward is  0.8\n",
      "in update_Q_values\n",
      "Q Values are updated\n",
      "Params Type: {<class 'str'>}\n",
      "Params Value: ('Happy',)\n",
      "with params\n",
      "query is : \n",
      "        SELECT TypeID, TypeName, TypeNameVector, Description, DescriptionVector,\n",
      "        create_by, create_dt, modified_by, modified_dt, active_flg\n",
      "        FROM lu_emotion_type WHERE TypeName = %s\n",
      "        \n",
      "state variables\n",
      "\n",
      "core_emotion is 1\n",
      "TypeID is 1\n",
      "current number of actions in the env  9647\n",
      "in get_reward\n",
      "user_id is  1\n",
      "exercise_id is  2956\n",
      "emotion_id is  3\n",
      "Params Type: {<class 'tuple'>}\n",
      "Params Value: [(1, 2956, 3)]\n",
      "with params\n",
      "query is : \n",
      "        SELECT * FROM user_exercise_feedback\n",
      "        WHERE user_id = %s AND exercise_id = %s AND emotion_id = %s\n",
      "        \n",
      "feedback_df is  <bound method NDFrame.head of    user_exercise_feedback_id  user_id  exercise_id  emotion_id  feedback  \\\n",
      "0                          1        1         2956           3         4   \n",
      "\n",
      "  create_by           create_dt modified_by modified_dt  active_flg  \n",
      "0     admin 2024-08-15 11:03:29        None        None           1  >\n",
      "reward is  0.8\n",
      "in update_Q_values\n",
      "Q Values are updated\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "from sqlalchemy import text\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        load_dotenv()\n",
    "        self.tidb_host = os.getenv(\"TIDB_HOST\", \"gateway01.us-east-1.prod.aws.tidbcloud.com\")\n",
    "        self.tidb_port = int(os.getenv(\"TIDB_PORT\", \"4000\"))\n",
    "        self.tidb_user = os.getenv(\"TIDB_USER\", \"EcFsmzHzn16sz32.root\")\n",
    "        self.tidb_password = os.getenv(\"TIDB_PASSWORD\", \"4UTXzVBKxU10w2Z1\")\n",
    "       # self.tidb_db_name = os.getenv(\"TIDB_DB_NAME\", \"embracepath\")\n",
    "        self.tidb_db_name = \"embracepath\"\n",
    "        self.ca_path = os.getenv(\"CA_PATH\", \"\")\n",
    "\n",
    "# Create environment and agent\n",
    "# Function to plot the learning history\n",
    "def plot_learning_history(history):\n",
    "    fig = plt.figure(1, figsize=(14, 10))\n",
    "    ax = fig.add_subplot(2, 1, 1)\n",
    "    episodes = np.arange(len(history))\n",
    "    moves = np.array([h[0] for h in history])\n",
    "    plt.plot(episodes, moves, lw=4, marker='o', markersize=10)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    plt.xlabel('Episodes', size=20)\n",
    "    plt.ylabel('# moves', size=20)\n",
    "    ax = fig.add_subplot(2, 1, 2)\n",
    "    rewards = np.array([h[1] for h in history])\n",
    "    plt.step(episodes, rewards, lw=4)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    plt.xlabel('Episodes', size=20)\n",
    "    plt.ylabel('Final rewards', size=20)\n",
    "    plt.savefig('q-learning-history.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_q_value_evolution(episodes, q_values):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(episodes, q_values, marker='o', linestyle='-', color='b')\n",
    "    plt.title('Q-Value Evolution Over Time')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Q-Value')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "def main():\n",
    "    config = Config()  # Make sure this is defined or imported correctly\n",
    "    db_service = DatabaseService(config)  # Ensure DatabaseService is correctly implemented\n",
    "    env = MindfulnessBanditEnv(num_features=3, db_service=db_service, num_actions=10)\n",
    "    \n",
    "    most_recent_state = env.get_most_recent_state()\n",
    "    print(\"most_recent_state is\", most_recent_state)\n",
    "    \n",
    "    \n",
    "    history = []\n",
    "    q_values_history = []  # List to store max Q-value of each episode for plotting\n",
    "    for episode in range(5):  # Adjust number of episodes for more significant learning data\n",
    "        state = env.reset()\n",
    "        print(\"current number of actions in the env \", env.num_actions)\n",
    "        \n",
    "        epsilon = 0.1  # 10% of the time actions are chosen randomly\n",
    "        if np.random.rand() < epsilon:\n",
    "            action = np.random.randint(0, 10)  # Random action\n",
    "        else:\n",
    "            action = np.argmax(env.Q_A)  # Best action based on current knowledge\n",
    "            \n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        history.append((episode, reward))\n",
    "        q_values_history.append(max(env.Q_A.values(), default=0))  # Capture max Q-value from Q_A or Q_B\n",
    "    env.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #actions = env.\n",
    "    #actions = env.get_exercises();\n",
    "    #print(\"actions length \", len(env.actions))\n",
    "    #print(\"number of actions is \", env.num_actions)\n",
    "   # env.update_action_space();\n",
    "   # print(\"actions length \", len(actions))\n",
    "    \n",
    "        \n",
    "        \n",
    "    # for episode in range(5):  # Adjust number of episodes for more significant learning data\n",
    "    #     state = env.reset()\n",
    "    #     action = np.random.randint(0, 10)  # Randomly choose an action\n",
    "    #     next_state, reward, done, _ = env.step(action)\n",
    "    #     history.append((episode, reward))\n",
    "    #     q_values_history.append(max(env.Q_A.values(), default=0))  # Capture max Q-value from Q_A or Q_B\n",
    "\n",
    "    #env.close()\n",
    "    # episodes = np.arange(len(q_values_history))  # Generate an array of episode numbers\n",
    "    # plot_q_value_evolution(episodes, q_values_history)\n",
    "    # plot_learning_history(history)  # Ensure this function is defined to plot rewards\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     config = Config()\n",
    "#     # https://www.meta.ai/c/a04b014a-ece0-4c51-9aa0-c51efb911727\n",
    "#     # for second set of eyes coding https://chatgpt.com/c/5264785b-a953-4241-b977-7a96b811d4bd\n",
    "#     db_service = DatabaseService(config)\n",
    "#     # The features are angry, sad, happy\n",
    "#     env = MindfulnessBanditEnv(num_features=3, db_service=db_service, num_actions=10)\n",
    "#     history = []\n",
    "#     for episode in range(5):  # Simulate 5 episodes\n",
    "#       #  print(\"before error\")\n",
    "#         state = env.reset()\n",
    "#       #  print(\"after error\")\n",
    "#         action = np.random.randint(0, 10)  # Randomly choose an action\n",
    "#      #   print(\"action is \", action)\n",
    "#         next_state, reward, done, _ = env.step(action)\n",
    "#         plot_q_value_evolution(episodes, q_values)\n",
    "\n",
    "#         history.append((episode, reward))\n",
    "#         print(f\"Episode {episode}: Action {action}, Reward {reward}\")\n",
    "#     env.close()\n",
    "#     plot_learning_history(history)    \n",
    "    \n",
    "# main()    "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m122"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
